from llm_interface import client as llm_client, OpenAIError # Import client and error

def verify_conceptual_match(actual_output: str, expected_concept: str, llm_model: str = "google/gemini-2.5-flash-preview") -> bool:
    """
    Uses an LLM to verify if the actual output conceptually matches the expected concept.

    Args:
        actual_output (str): The output generated by the system.
        expected_concept (str): A description of the expected meaning.
        llm_model (str): The LLM model to use for verification.

    Returns:
        bool: True if the LLM confirms conceptual equivalence, False otherwise.
    """
    if not llm_client:
        print("Warning: LLM client not available for conceptual verification. Skipping check.")
        return True # Avoid test failure if LLM is down, but log a warning

    prompt = f"""Does the following 'Actual Output' convey the same core meaning as the 'Expected Concept'?
Focus ONLY on the conceptual equivalence regarding the core information (e.g., probabilities, causes identified). Ignore minor phrasing differences, formatting, or conversational filler like 'Okay, I've added...'.
Respond ONLY with "YES" or "NO".

Expected Concept: {expected_concept}

Actual Output: {actual_output}

Response:"""

    try:
        response = llm_client.chat.completions.create(
            model=llm_model,
            messages=[
                {"role": "system", "content": "You are a conceptual equivalence checker. Respond ONLY with YES or NO."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=5, # Should only need YES or NO
            temperature=0.0,
            n=1,
            stop=None,
        )
        llm_response = response.choices[0].message.content.strip().upper()
        # Updated print statement
        print(f"[Conceptual Equality Check] Expected: '{expected_concept}' | Actual: '{actual_output}' | LLM Response: '{llm_response}'")
        return llm_response == "YES"
    except OpenAIError as e:
        print(f"[Conceptual Equality Check] Warning: LLM API error during conceptual verification: {e}. Skipping check.")
        return True # Avoid test failure on API error
    except Exception as e:
        print(f"Warning: Unexpected error during conceptual verification: {e}. Skipping check.")
        return True # Avoid test failure on other errors
